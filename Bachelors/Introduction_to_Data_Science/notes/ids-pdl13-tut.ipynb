{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**ids-pdl13-tut.ipynb**: This Jupyter notebook is provided by Joachim Vogt for the *Python Data Lab* of the module *CH-700 Introduction to Data Science* offered in Fall 2023 at Constructor University. Jupyter notebooks and other learning resources are available from a dedicated *module platform*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elements of image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial introduces Python tools for displaying and processing images in the context of planetary remote sensing. Follow the instructions below to learn to\n",
    "\n",
    "- [ ] understand basic image formats and display options,\n",
    "- [ ] apply geometry transformations and intensity scaling to images,\n",
    "- [ ] use local filters for denoising, smoothing, and edge detection.\n",
    "\n",
    "If you wish to keep track of your progress, you may edit this markdown cell, check a box in the list above after having worked through the respective part of this notebook, and save the file.\n",
    "\n",
    "Only selected basic elements of image processing are covered. For more information, see the suggestions for further reading that are embedded in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code cell to import standard Python data science libraries. The NumPy module facilitates efficient processing of numerical arrays, and is usually imported as `np`. From the matplotlib library we import the package `pyplot` using the standard abbreviation `plt`. Image processing tools are provided in several libraries such as `scipy.ndimage`, `imagio`, `PIL.Image`, and `PIL.ImageFilter`. The magic command `%matplotlib inline` (IPython shell) allows for inline display of graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import imageio.v2 as imageio\n",
    "from PIL import Image, ImageFilter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following data files are expected to reside in the working directory. Identify the files on the module platform and upload them to the same folder as this Jupyter notebook.\n",
    "\n",
    "- `PIA01141.tif`: grayscale image of a region on Mars containing the geologic _Face on Mars_ formation, photographed by NASA's Viking 1 Orbiter on July 25, 1976. The file is available from [NASA's JPL Photojournal website](https://photojournal.jpl.nasa.gov/catalog/PIA01141).\n",
    "- `march2014_1920x1200.jpeg`: [color image](https://www.nasa.gov/sites/default/files/thumbnails/image/march2014_1920x1200.jpeg) (Credit: NASA/USGS Landsat; Geoscience Australia) featured on [this NASA website](https://www.nasa.gov/image-feature/color-explosion-beautiful-earth). The source image was taken in May 2013 by the Landsat 8 satellite over Western Australia, and then enhanced. \n",
    "- `mgn_volc.gif`: [section of a Magellan radar image](https://nssdc.gsfc.nasa.gov/planetary/mgn_volc.gif) as described on the page [Magellan Mission to Venus](https://nssdc.gsfc.nasa.gov/planetary/magellan.html).\n",
    "- `mgn_volc.png`: png version of `mgn_volc.gif`.\n",
    "- `vo1_890a68.tiff`: image  taken by the Viking 1 Orbiter, showing the largest mountain of the solar system, namely, the Olympus Mons volcano on Mars. Available from [this NASA website](https://nssdc.gsfc.nasa.gov/imgcat/html/object_page/vo1_890a68.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to digital images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section illustrates the array structure of grayscale and color images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grayscale images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-dimensional arrays (matrices) can be displayed as images, e.g., by means of the matplotlib function `imshow()`. In contrast to `contour()` or `contourf()`, `imshow()` interpretes array elements as square pixels, and the aspect ratio is preserved. Furthermore, the pixels on the vertical axis are reversed, with zero at the top. Note that `imshow()` uses the default color map (keyword `cmap`). To enforce grayscale displays, set `cmap` to `plt.cm.gray`, or to the string variable 'gray'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.meshgrid(np.linspace(-2,2,201),np.linspace(-1,1,201))\n",
    "f = 100*(1 + np.exp(-x**2)*np.sin(2*np.pi*y))\n",
    "print('Shape of the array f: ',f.shape)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(221)\n",
    "plt.contour(f)\n",
    "plt.colorbar()\n",
    "plt.title('$f(x,y)$ displayed using contour')\n",
    "plt.subplot(222)\n",
    "plt.contourf(f)\n",
    "plt.colorbar()\n",
    "plt.title('$f(x,y)$ displayed using contourf')\n",
    "plt.subplot(223)\n",
    "plt.imshow(f)\n",
    "plt.colorbar()\n",
    "plt.title(\"$f(x,y)$ displayed using imshow, default cmap\")\n",
    "plt.subplot(224)\n",
    "plt.imshow(f,cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title(\"$f(x,y)$ displayed using imshow, cmap='gray'\")\n",
    "#---plt.savefig('contourf_imshow.png',facecolor=None,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with image display functions of other Python modules, the matplotlib function `imshow()` does not require the image intensity values to be of dtype `unit8` (value range 0-255), and it also applies some automatic rescaling. In the following, display of the full intensity range will be enforced (`vmin=0,vmax=255`) unless otherwise stated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color images are stored in several two-dimensional arrays. Each of the arrays (also called channels) represents one color according to a color model, typically RGB (red-green-blue). A four-channel version of the RGB model is RGBA, with the channel A (alpha) quantifying transparency.\n",
    "\n",
    "Load the [image file](https://www.nasa.gov/sites/default/files/thumbnails/image/march2014_1920x1200.jpeg) (Credit: NASA/USGS Landsat; Geoscience Australia) featured on [this NASA website](https://www.nasa.gov/image-feature/color-explosion-beautiful-earth). The source image was taken in May 2013 by the Landsat 8 satellite over Western Australia, and then enhanced. Convince yourself that the data consist of three two-dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = imageio.imread('march2014_1920x1200.jpeg')\n",
    "print('Shape of the array arr: ',arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the full image, and then the three color channels in grayscale. Note the convention shared by matrices and images: the number of rows (here: 1200, `axis=0`) corresponds to the number of pixels in the vertical dimension, and the number of columns (here: 1920, `axis=1`) to the number of pixels in the horizontal dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(arr,vmin=0,vmax=255)\n",
    "colstr = ['(red)','(green)','(blue)']\n",
    "plt.title('Color image: all channels')\n",
    "plt.ylabel('Vertical dimension [pixels]')\n",
    "for k in range(3):\n",
    "    plt.subplot(2,2,k+2)\n",
    "    plt.imshow(arr[...,k],cmap='gray',vmin=0,vmax=255)\n",
    "    plt.title('Color image: channel {} '.format(k)+colstr[k])\n",
    "    if k>0: plt.xlabel('Horizontal dimension [pixels]')\n",
    "    if 1==k%2: plt.ylabel('Vertical dimension [pixels]')\n",
    "#---plt.savefig('color_channels.png',facecolor=None,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color images can be converted to grayscale using the function `convert()` from the Pillow library `PIL.Image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('march2014_1920x1200.jpeg').convert('L')\n",
    "img.save('march2014_1920x1200_grayscale.png')\n",
    "arr_gray = imageio.imread('march2014_1920x1200_grayscale.png')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(arr_gray,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Color image converted to grayscale')\n",
    "plt.xlabel('Horizontal dimension [pixels]')\n",
    "plt.ylabel('Vertical dimension [pixels]')\n",
    "print('Shape of the array arr_gray: ',arr_gray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grayscale images may be offered in color file formats for compatibility reasons, with all color channels containing the same data (possibly supplemented by the alpha channel of the RGBA model), see e.g. the file `mgn_volc.png` on the module platform converted from [mgn_volc.gif](https://nssdc.gsfc.nasa.gov/planetary/mgn_volc.gif) showing a section of a Magellan radar image as described on the page [Magellan Mission to Venus](https://nssdc.gsfc.nasa.gov/planetary/magellan.html). In the code cell below, the converted image is stored in proper grayscale format for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = imageio.imread('mgn_volc.png')\n",
    "print('Shape of the array arr: ',arr.shape)\n",
    "img = Image.open('mgn_volc.png').convert('L')\n",
    "img.save('mgn_volc_grayscale.png')\n",
    "arr_gray = imageio.imread('mgn_volc_grayscale.png')\n",
    "print('Shape of the array arr_gray: ',arr_gray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image opened with the module `PIL.Image` can be displayed in a Jupyter notebook using the built-in function `display()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further reading: Introduction to digital images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To familiarize further with the basic concepts of digital image processing in Python, consult the documentation and web resources, e.g., the [SciPy lecture notes](https://scipy-lectures.org/advanced/image_processing/) and the [documentation of the Pillow module (PIL)](https://pillow.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we distinguish between transformations of the image geometry (region extractions or cropping, rotations) and scalings of image intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometry transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping an image corresponds to extracting a sub-array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = imageio.imread('mgn_volc_grayscale.png')\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(arr,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Full image')\n",
    "plt.subplot(122)\n",
    "arr_crop = arr[150:350,200:400]\n",
    "plt.imshow(arr_crop,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Cropped image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cropping operation is implemented also in the `PIL.Image` function `crop()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = Image.open('mgn_volc_grayscale.png')\n",
    "img_cropped = img.crop((200,150,400,350))\n",
    "display(img_cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PIL.Image` module contains further functions for geometry transformations, e.g., for flipping or rotating an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rot45 = img_cropped.rotate(45)\n",
    "display(img_rot45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intensity scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When intensity values are concentrated in a narrow interval, one may map them onto the full intensity range for enhancing the image contrast. The histogram of the transformed image then shows a broader distribution (histogram equalization).\n",
    "\n",
    "In the example below, the histogram of the original image shows that intensity values are mainly in the interval $[100,170]$. To display the image with enhanced contrast, the keywords `vmin` and `vmax` of `plt.imshow()` are chosen accordingly ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = imageio.imread('mgn_volc_grayscale.png')\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(arr,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Original image')\n",
    "plt.subplot(132)\n",
    "plt.hist(arr.flatten())\n",
    "plt.title('Histogram of flattened array')\n",
    "plt.subplot(133)\n",
    "plt.imshow(arr,cmap='gray',vmin=100,vmax=170)\n",
    "plt.colorbar()\n",
    "plt.title('Contrast enhancement')\n",
    "#---plt.savefig('contrast_enhancement.png',facecolor=None,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intensity values can also be rescaled numerically, and the result then displayed using the full intensity range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.. effective range of intensity values in the original image\n",
    "oldmin = 100\n",
    "oldmax = 170\n",
    "#.. range of intensity values for rescaling\n",
    "newmin = 0\n",
    "newmax = 255\n",
    "#.. rescaling formula requires floating operations\n",
    "arr_f64 = np.asarray(arr,dtype=np.float64)\n",
    "arr_hst_f64 = newmin + (arr_f64-oldmin)*(newmax-newmin)/(oldmax-oldmin)\n",
    "#.. convert back to byte array\n",
    "arr_hst = np.asarray(arr_hst_f64,dtype=np.int32)\n",
    "#.. map invalid intensity to 0 (black) and 255 (white)\n",
    "arr_hst[arr_hst<newmin] = newmin\n",
    "arr_hst[arr_hst>newmax] = newmax\n",
    "#.. reproduce the previous plot to check\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(arr,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Original image')\n",
    "plt.subplot(132)\n",
    "plt.hist(arr.flatten())\n",
    "plt.title('Histogram of flattened array')\n",
    "plt.subplot(133)\n",
    "plt.imshow(arr_hst,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Contrast enhancement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further reading: Histogram-based techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consult the [SciPy lecture notes](https://scipy-lectures.org/advanced/image_processing/) to learn about histogram equalization and histogram-based segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoothing and edge detection are two operations where local filters are applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate how noise reduction in images can be achieved through local filtering, we consider the file [PIA01141.tif](https://photojournal.jpl.nasa.gov/catalog/PIA01141), \n",
    "showing a region on Mars photographed by NASA's Viking 1 Orbiter spacecraft in July 1976 (Credit:NASA/JPL). The image is contaminated by salt-and-peppers noise due to bit errors. We focus on the region containing a surface feature called the _Face on Mars_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_full = Image.open('PIA01141.tif')\n",
    "arr_full = np.asarray(img_full)\n",
    "arr = arr_full[80:200,280:400]\n",
    "plt.imshow(arr,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SciPy module `ndimage` offers a range of filters. A Gaussian filter reduces the salt-and-pepper noise but affects strongly also the edges in the image. A median filter is better suited to deal with this kind of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_gf = ndimage.gaussian_filter(arr,3)\n",
    "arr_mf = ndimage.median_filter(arr,5)\n",
    "plt.figure(figsize=(13,3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(arr,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Original image')\n",
    "plt.subplot(132)\n",
    "plt.imshow(arr_gf,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Gaussian filter (size 3)')\n",
    "plt.subplot(133)\n",
    "plt.imshow(arr_mf,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Median filter (size 5)')\n",
    "#---plt.savefig('noise_reduction.png',facecolor=None,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoothing filters are implemented also in the `PIL` module `ImageFilter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('PIA01141.tif').crop((280,80,400,200))\n",
    "img_mfpil = img.filter(ImageFilter.MedianFilter(5))\n",
    "arr_mfpil = np.asarray(img_mfpil)\n",
    "plt.imshow(img_mfpil,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Median filter (size 5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection and sharpening can be achieved by derivative operators such as the Sobel (first derivative) or Roberts (second derivative) filters.\n",
    "\n",
    "In the code cell below, we demonstrate edge detection as implemented in the `PIL` module `ImageFilter`. The image file [vo1_890a68.tiff](https://nssdc.gsfc.nasa.gov/imgcat/html/object_page/vo1_890a68.html) was taken by the Viking 1 Orbiter. It shows the largest mountain of the solar system, namely,  the Olympus Mons volcano on Mars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = Image.open('vo1_890a68.tiff')\n",
    "img_edges = img.filter(ImageFilter.FIND_EDGES)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Olympus Mons')\n",
    "plt.subplot(122)\n",
    "arr_edges_inv = 255 - np.asarray(img_edges)\n",
    "plt.imshow(arr_edges_inv,cmap='gray',vmin=0,vmax=255)\n",
    "plt.colorbar()\n",
    "plt.title('Edge detection')\n",
    "#---plt.savefig('edge_detection.png',facecolor=None,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further reading: Local filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the application of local filters in image processing, read the [Wikipedia article on Mathematical morphology](https://en.wikipedia.org/wiki/Mathematical_morphology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
