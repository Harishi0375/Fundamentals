{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**ids-pdl12-tut.ipynb**: This Jupyter notebook is provided by Joachim Vogt for the *Python Data Lab* of the module *CH-700 Introduction to Data Science* offered in Fall 2023 at Constructor University. Jupyter notebooks and other learning resources are available from a dedicated *module platform*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial introduces Python tools for displaying empirical statistical distributions and their theoretical counterparts as well as hypothesis testing. Follow the instructions below to learn to\n",
    "\n",
    "- [ ] generate sequences of random numbers using the NumPy module `random`,\n",
    "- [ ] construct and display empirical distributions in the form of histograms,\n",
    "- [ ] approximate probability density functions using kernel density estimators,\n",
    "- [ ] work with important methods of the SciPy module `stats`,\n",
    "- [ ] understand hypothesis testing and apply $z$ tests and Student's t tests to data,\n",
    "- [ ] check the normality assumption using hypothesis tests and probability plots.\n",
    "\n",
    "If you wish to keep track of your progress, you may edit this markdown cell, check a box in the list above after having worked through the respective part of this notebook, and save the file.\n",
    "\n",
    "*Short exercises* are embedded in this notebook. *Sample solutions* can be found at the end of the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code cell to import standard Python data science libraries. The NumPy module facilitates efficient processing of numerical arrays, and is usually imported as `np`. From the matplotlib library we import the package `pyplot` using the standard abbreviation `plt`. The SciPy module `stats` provides a variety of statistical tools and functions. The magic command `%matplotlib inline` (IPython shell) allows for inline display of graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-random number generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistical data analysis and modeling, pseudo-random number generators are frequently used, e.g., to study statistical operations by means of synthetic measurements (also called surrogate data) drawn from a given distribution. Two important distributions considered here are the uniform distribution and the normal (Gaussian) distribution. Before we look at how they are implemented in Python, let us review a few theoretical concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random variables and statistical distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that measurements and their errors are modeled by *random processes*, and their outcomes by random variables. For *continuous random variables*, probabilities do not refer to single values but to ranges of values. With the probability to find a continuous random variable $U$ in the range $[a,b]$ denoted as $\\mathrm{Prob} (a \\le U \\le b)$, the *cumulative distribution function (CDF)* $\\Phi$ is defined through $\\Phi (u) = \\mathrm{Prob} (U \\le u)$, i.e., it is the probability that the random variable $U$ assumes a value smaller than or equal to the number $u$.\n",
    "\n",
    "If the cumulative distribution function $\\Phi = \\Phi(u)$ is a smooth (differentiable) function, then its derivative\n",
    "$$\n",
    "p(u) \\; = \\; \\frac{\\mathrm{d} \\Phi}{\\mathrm{d} u} \\, = \\, \\Phi'(u) \n",
    "$$\n",
    "is called *probability density function (PDF)*, but also density, distribution function, or simply distribution.\n",
    "\n",
    "- The PDF is *non-negative*: $p(u) \\ge 0$.\n",
    "- $\\mathrm{Prob} (a \\le U \\le b) \\, = \\, \\Phi(b) - \\Phi(a) \\, = \\, \\int_a^b p(u) \\, \\mathrm{d} u ~.$\n",
    "- *Normalization*: $\\int_{-\\infty}^{\\infty} p(u) \\, \\mathrm{d} u \\, = \\, 1 ~.$\n",
    "\n",
    "*Quantiles* divide the range of a distribution into intervals of equal probability, and are obtained as solutions $u$ of $\\Phi(u) = q$ with predefined probabilities $q$, thus $u = \\Phi^{-1}(q)$. The *quantile function* or *percent point function (PPF)* is the inverse of the CDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal distribution is characterized by two parameters, namely, the mean $u_0$ and the standard deviation $\\sigma$. Its PDF is given by\n",
    "$$\n",
    "p(u) \\, = \\, \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-(u - u_0)^2/2\\sigma^2} ~.\n",
    "$$\n",
    "The function `normal()` from the NumPy module `random` generates (pseudo-)random numbers according to the normal distribution, with the mean $u_0$ and the standard deviation $\\sigma$ defined through the keyword parameters `loc` and `scale`. A third keyword parameter `size` allows for specifying the length of the shape of the output array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.normal(loc=10,scale=10,size=(2,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard normal distribution has zero mean and unit variance:\n",
    "$$\n",
    "p(u) \\, = \\, \\frac{1}{\\sqrt{2\\pi}} e^{-u^2/2} ~.\n",
    "$$\n",
    "Random numbers according to the standard normal distribution are generated conveniently by means of the functions `standard_normal()` or `randn()`, also from the NumPy module `random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.standard_normal(5))\n",
    "print(np.random.randn(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniform distributions are non-zero and constant in an interval $[a,b]$, and zero otherwise:\n",
    "$$\n",
    "p(u) \\, = \\, \n",
    "\\left\\{ \n",
    "\\begin{array}{ccl} \n",
    "\\frac{1}{b-a} & \\text{if} & u \\in [a,b] ~, \\\\\n",
    "0             & \\text{if} & u \\notin [a,b] ~.\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "The function `uniform()` from the NumPy module `random` generates uniform random numbers with the keyword parameters `low` and `high` set to $a$ and $b$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import uniform\n",
    "print(np.random.uniform(low=10,high=20,size=(2,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard uniform distribution yields values in the interval $[a,b] = [0,1]$. Random number generators from the NumPy module `random` for this distribution are `random()`, `random_sample()`, and `rand()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.random(5))\n",
    "print(np.random.random_sample(5))\n",
    "print(np.random.rand(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator instance and seed values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While functions for random number generation can be called in the usual manner as demonstrated above, it is recommended to create random numbers from an instance of a Generator class produced by the constructor function `default_rng()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "print(rng.random(5))\n",
    "print(rng.standard_normal(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `default_rng()` accepts a seed parameter to initialize the random number sequence to a controlled state. The same random number sequence may be reproduced for test purposes, as one can see by repeatedly running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "rng = np.random.default_rng(seed)\n",
    "rng.random(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An empirical distribution constructed from the data is a statistical estimator for the PDF of the underlying random process. The procedure of constructing such an empirical distribution is called *density estimation*. A simple and popular density estimator is the *histogram*, collecting data into predefined intervals called *bins*. The resulting occurence frequencies are plotted as a step function using the `hist()` method from `matplotlib.pyplot`. The keyword `density` normalizes the output so that it can be graphically compared to the theoretical PDF. The keyword `bins` gives the number of intervals and thus controls the resolution of the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(99)\n",
    "u = rng.standard_normal(1000)\n",
    "x = np.linspace(-4,4,81)\n",
    "d = np.exp(-x**2/2)/np.sqrt(2*np.pi)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(x,d,label='Theoretical PDF')\n",
    "plt.hist(u,bins=20,density=True,label='Empirical PDF')\n",
    "plt.title('Gaussian distribution and random numbers: histogram')\n",
    "plt.xlim((-4,4))\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More refined than histograms are *kernel density estimators (KDEs)* which acculumate contributions from predefined functions (kernels) around the data. KDE implementations exist in several Python packages. Here we choose ``kdeplot()`` from the seaborn module. The type of kernel and the resolution can be controlled by means of the keywords `kernel` and `bw`, respectively. See the documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import kdeplot\n",
    "rng = np.random.default_rng(99)\n",
    "u = rng.standard_normal(1000)\n",
    "x = np.linspace(-4,4,81)\n",
    "d = np.exp(-x**2/2)/np.sqrt(2*np.pi)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(x,d,label='Theoretical PDF')\n",
    "kdeplot(u,fill=True,label='Empirical PDF')\n",
    "plt.title('Gaussian distribution and random numbers: KDE plot')\n",
    "plt.xlim((-4,4))\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same parameters as for the standard normal distribution example, create a set of random numbers following the standard uniform distribution, then a histogram plot and a KDE plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random variables as provided by `scipy.stats`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SciPy module `stats` provides an environment for working with random variables. Consult the [user guide](https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html) and the \n",
    "[reference manual](https://docs.scipy.org/doc/scipy/reference/reference/stats.html#statsrefmanual) for an introduction to the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Uniform distribution in `scipy.stats`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the attributes and methods associated with the continuous random variables class in the SciPy module `stats`, consider the uniform distribution on an interval $[a,b]$ as implemented in `scipy.stats.uniform()`. The keyword arguments `loc` and `scale` correspond to the startpoint $a$ and the interval length $b-a$, respectively. To obtain an overview of further parameters and methods associated with `scipy.stats.uniform()`, uncomment the line in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.stats.uniform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, the support and basic statistics for the default case (default parameters `loc=0` and `scale=1`, support $[0,1]$) can be obtained directly from the corresponding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Support:',scipy.stats.uniform.support())\n",
    "m,v,s,k = scipy.stats.uniform.stats(moments='mvsk')\n",
    "print('Moments: m={:.2f}, v={:.4f}, s={:.2f}, k={:.3f}'.format(m,v,s,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one may first create a so-called *frozen* (continuous) random variable, and then call suitable methods to compute statistics. This approach is exemplified below, using a shifted (`loc=-1`) and stretched (`scale=2`) version of the standard uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uniform distribution on [0,1]\n",
    "print('Uniform distribution on [0,1]')\n",
    "urv1 = scipy.stats.uniform()\n",
    "print('* Support:',urv1.support())\n",
    "m,v,s,k = urv1.stats(moments='mvsk')\n",
    "print('* Moments: m={:.2f}, v={:.4f}, s={:.2f}, k={:.3f}'.format(m,v,s,k))\n",
    "print()\n",
    "### Uniform distribution on [-1,1]\n",
    "print('Uniform distribution on [-1,1]')\n",
    "uloc = -1\n",
    "usca = 2\n",
    "urv2 = scipy.stats.uniform(loc=uloc,scale=usca)\n",
    "print('* Support:',urv2.support())\n",
    "m,v,s,k = urv2.stats(moments='mvsk')\n",
    "print('* Moments: m={:.2f}, v={:.4f}, s={:.2f}, k={:.3f}'.format(m,v,s,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the probability density functions (PDFs) for both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2,2,81)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.title('Probability density functions (PDFs)')\n",
    "plt.plot(x,urv1.pdf(x),'b-',lw=3,label='Uniform on {}'.format(urv1.support()))\n",
    "plt.plot(x,urv2.pdf(x),'r-',lw=3,label='Uniform on {}'.format(urv2.support()))\n",
    "plt.xlim([-2,2])\n",
    "plt.ylim([0.0,1.1])\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the cumulative distribution functions (CDFs) for both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2,2,81)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.title('Cumulative distribution functions (CDFs)')\n",
    "plt.plot(x,urv1.cdf(x),'b-',lw=3,label='Uniform on {}'.format(urv1.support()))\n",
    "plt.plot(x,urv2.cdf(x),'r-',lw=3,label='Uniform on {}'.format(urv2.support()))\n",
    "plt.xlim([-2,2])\n",
    "plt.ylim([0.0,1.1])\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the percent point functions (PPFs) for both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.linspace(0,1,81)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.title('Percent point functions (PPFs)')\n",
    "plt.plot(q,urv1.ppf(q),'b-',lw=3,label='Uniform on {}'.format(urv1.support()))\n",
    "plt.plot(q,urv2.ppf(q),'r-',lw=3,label='Uniform on {}'.format(urv2.support()))\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([-1,1])\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Normal distribution in `scipy.stats`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the standard normal distribution and repeat the sequence of steps from the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random number generation in `scipy.stats`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `scipy.stats` terminology, random numbers are referred to as random variates, and generated by means of the method `rvs()`. In the cell below, a sequence of uniformly distributed random numbers is created. The resulting histogram is displayed against the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2,2,81)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.title('Histogram and model distribution')\n",
    "plt.plot(x,urv2.pdf(x),'r-',lw=3,label='Uniform pdf')\n",
    "data = urv2.rvs(size=20)\n",
    "bins = np.linspace(-1,1,5)\n",
    "plt.hist(data,bins=bins,color='red',\\\n",
    "         alpha=0.3,density=True,label='Random variates')\n",
    "plt.xlim([-2,2])\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the set of random variates as input data, one can fit the parameters of the uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_est,scale_est = scipy.stats.uniform.fit(data)\n",
    "print('Estimated location (lower bound of uniform distr. :',loc_est)\n",
    "print('Estimated scale (upper bound minus lower bound)   :',scale_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiatizing random number sequences in a reproducible manner is possible also in `scipy.stats`. Consult the documentation on `RandomState` and `Generator` objects in NumPy, and how to import the information in `scipy.stats`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normally distributed random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare for hypothesis testing, let us review and illustrate important properties of the normal (Gaussian) distribution.\n",
    "\n",
    "A normally distributed random variable $U$ is fully characterized by the mean $\\mu = \\bar{U}$ and the standard deviation $\\sigma = \\Delta U$. The probability to find a measurement of $U$ in the range $[\\mu-z\\sigma,\\mu+z\\sigma]$ is given by\n",
    "$$\n",
    "\\gamma \\, = \\, \\mathrm{Prob} (\\mu-z\\sigma \\le U \\le \\mu + z\\sigma) \n",
    "\\, = \\, \\Phi (z) - \\Phi(-z) \n",
    "\\, = \\, 2 \\Phi (z) - 1 \n",
    "$$\n",
    "where $\\Phi$ denotes the cumulative distribution function of the standard normal distribution with zero mean ($\\mu=0$) and unit variance ($\\sigma=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing $z=2$ gives $\\mathrm{Prob} (\\mu-2\\sigma \\le U \\le \\mu + 2\\sigma) = 0.9545$, hence the probability that a measurement ends up within $\\pm 2 \\sigma$ around the mean $\\mu$ is larger than $95\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 2\n",
    "gamma = scipy.stats.norm.cdf(z) - scipy.stats.norm.cdf(-z)\n",
    "print('Probability gamma for z = {:.2f} : gamma = {:.2f}%'.format(z,gamma*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One may also ask how many ($z$) standard deviations ($\\sigma$) around the mean ($\\mu$) must be considered to arrive at a given probability. To this end, one may employ the percent point function $\\Phi^{-1}$ (inverse CDF). The number $z$ is then given by\n",
    "$$\n",
    "z \\; = \\; \n",
    "\\Phi^{-1} \\left( \\frac{1+\\mathrm{Prob} (\\mu-z\\sigma \\le U \\le \\mu + z\\sigma)}{2} \\right) \n",
    "\\; = \\; \\Phi^{-1} \\left( \\frac{1+\\gamma}{2} \\right) ~.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.95\n",
    "z = scipy.stats.norm.ppf(0.5*(1+gamma))\n",
    "print('Score z for probability gamma = {:.2f}% : z = {:.2f}'.format(gamma*100,z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hypothesis testing* is a method in inferential statistics with the following elements.\n",
    "\n",
    "- Formulate a *null hypothesis* $H_0$ and (at least implicitly) an alternative hypothesis $H_1$ referring to a testable property of the distribution.\n",
    "- Define a *test statistic* $T$ sensitive to differences between $H_0$ and $H_1$.\n",
    "- Choose a *significance level* $\\alpha$ (maximum tolerated false positive rate).\n",
    "- For the chosen test statistic $T$, find the value $t$ from the sample.\n",
    "- Compute the *probability value* ($p$ value): probability that an empirical estimate of $T$ is at least as extreme as the observed value $t$. \n",
    "- The null hypothesis $H_0$ is rejected (in favor of $H_1$) if $p < \\alpha$.\n",
    "- *Type I error*: a true null hypothesis is rejected (false positive).\n",
    "- *Type II error*: a false null hypothesis is not rejected (false negative).\n",
    "\n",
    "*Examples of statistical tests*\n",
    "\n",
    "- $z$ tests: under $H_0$, the test statistic is normally distributed.\n",
    "- Student's $t$ tests: under $H_0$, the test statistic $T$ follows a Student's $t$ distribution.\n",
    "- Normality tests: check if a sample is drawn from a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples below, the standard choice for the significance level $\\alpha$ is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = SignificanceLevel = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $z$ tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This category summarizes statistical hypothesis tests where under the null hypothesis $H_0$, the test statistic $Z$ is normally distributed: $Z \\sim \\mathcal{N} (\\mu,\\sigma^2)$. $Z$ tests are often used as so-called location (mean $\\mu$) tests when either the scale (standard deviation $\\sigma$) is known, or the sample size $N$ is large enough for the exact (Student's $t$) distribution to be well approximated by a normal distribution. The test statistic $Z$ is the scaled difference between the sample mean $\\bar{u}$ and $\\mu$: \n",
    "$$\n",
    "Z \\, = \\, \\frac{\\bar{u}-\\mu}{\\sigma/\\sqrt{N}} \\, \\sim \\, \\mathcal{N} (0,1) ~.\n",
    "$$\n",
    "Under the null hypothesis $H_0$ it is assumed that the sample mean $\\bar{u}$ does not show a significant difference from the true mean $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the test procedure, we first generate a sample of normally distributed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the true parameters of the underlying normal distribution.\n",
    "TrueMean = 3\n",
    "TrueStd = 5\n",
    "### Obtain a sample drawn from the underlying normal distribution.\n",
    "N = SampleSize = 100\n",
    "data = scipy.stats.norm.rvs(loc=TrueMean,scale=TrueStd,size=SampleSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the sample mean $\\bar{u}$ and the resulting value $z$ of the test statistic $Z$. Using the cumulative distribution function (CDF) $\\Phi$ of the standard normal distribution, we obtain the probability ($p$ value) of getting a value at least as extreme (small or large) as $\\bar{u}$ in the theoretical distribution of sample means:\n",
    "$$\n",
    "p \\, = \\, \\Phi(-|z|) + \\left[ 1 - \\Phi(|z|) \\right] \n",
    "\\, = \\, 2 \\Phi(-|z|) ~.\n",
    "$$\n",
    "This kind of test is called *two-tailed* because the rejection region comprises both the left (lower) tail of the distribution (area $\\Phi(-|z|)$) and right (upper) tail (area $1 - \\Phi(|z|) = \\Phi(-|z|)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('True mean           : {:3f}'.format(TrueMean))\n",
    "print('Sample size         : {}'.format(SampleSize))\n",
    "### Compute the sample mean.\n",
    "SampleMean = np.mean(data)\n",
    "print('Sample mean         : {:3f}'.format(SampleMean))\n",
    "### Compute the test statistic.\n",
    "TestStat = (SampleMean-TrueMean)/(TrueStd/np.sqrt(SampleSize))\n",
    "### Compute the probability value (p value).\n",
    "ProbVal = 2*scipy.stats.norm.cdf(-np.abs(TestStat))\n",
    "print('* Test statistic    : {:3f}'.format(TestStat))\n",
    "print('* Probability value : {:3f}'.format(ProbVal))\n",
    "### Check how the p value compares with the significance level alpha.\n",
    "if ProbVal >= alpha:\n",
    "    print('No significant difference between sample mean and true mean.')\n",
    "else:\n",
    "    print('Statistically significant difference between sample mean and true mean.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in this case the sample is drawn from the stated underlying distribution, we expect that in most cases (confidence level $\\gamma = 1 - \\alpha$) the null hypothesis is not rejected, i.e., the sample mean does not differ significantly from the true mean. To check this expectation, we repeat the procedure using a large set of samples, and plot the distribution of $p$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the true parameters of the underlying normal distribution.\n",
    "TrueMean = 3\n",
    "TrueStd = 5\n",
    "### Initialize arrays to store statistics of the ensemble of samples.\n",
    "N = SampleSize = 100\n",
    "NumSamples = 1000\n",
    "SampleMeanArr = np.zeros(NumSamples)\n",
    "TestStatArr = np.zeros(NumSamples)\n",
    "ProbValArr = np.zeros(NumSamples)\n",
    "### Create arrays with sample statistics and test statistics.\n",
    "for k in range(NumSamples):\n",
    "    data = scipy.stats.norm.rvs(loc=TrueMean,scale=TrueStd,size=SampleSize)\n",
    "    SampleMeanArr[k] = np.mean(data)\n",
    "    TestStatArr[k] = (SampleMeanArr[k]-TrueMean)/(TrueStd/np.sqrt(SampleSize))\n",
    "    ProbValArr[k] = 2*scipy.stats.norm.cdf(-np.abs(TestStatArr[k]))\n",
    "### Open plot figure.\n",
    "plt.figure(figsize=(11,4))\n",
    "### Plot distribution of test statistics.\n",
    "plt.subplot(1,2,1)\n",
    "epdf,bins,pats = plt.hist(TestStatArr,20,density=True)\n",
    "plt.plot(bins,scipy.stats.norm.pdf(bins),color='orange')\n",
    "plt.title('Distribution of test statistics')\n",
    "plt.xlabel(r'Test statistic $z$')\n",
    "plt.ylabel('Normed PDF')\n",
    "zCrit = scipy.stats.norm.ppf(alpha/2)\n",
    "plt.plot([zCrit,zCrit],[0,scipy.stats.norm.pdf(zCrit)],color='red')\n",
    "plt.plot([-zCrit,-zCrit],[0,scipy.stats.norm.pdf(-zCrit)],color='red')\n",
    "### Plot distribution of probability values.\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(ProbValArr,20)\n",
    "ylimits = plt.gca().get_ylim()\n",
    "plt.plot([alpha,alpha],ylimits,color='red')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim(ylimits)\n",
    "plt.title(r'Distribution of $p$ values (two-tailed $z$ test)')\n",
    "plt.xlabel('Binned $p$ values')\n",
    "plt.ylabel('Occurence frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left diagram shows the empirical (blue histogram) and theoretical (orange line) distributions of the test statistic $z$. The two rejection regions are marked by two vertical red lines. The right diagram displays the (supposedly uniform) empirical distribution of $p$ values. Here the vertical red line gives the signficance level. The region to the left of the red line contains the cases where the sample means are so extreme that the resulting $p$ values are below the pre-selected significance level $\\alpha$, and the null hypothesis $H_0$ is erroneously rejected (population of false positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: $z$ test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the procedure using random variates from a standard uniform distribution on the interval $[0,1]$. Note the mean is $\\mu=\\frac{1}{2}$, and the variance is $\\sigma^2 = \\frac{1}{12}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student's $t$ test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This category summarizes statistical hypothesis tests where under the null hypothesis $H_0$, the test statistic \n",
    "$$\n",
    "T \\, = \\, \\frac{\\bar{u}-\\mu}{\\sigma/\\sqrt{N}}\n",
    "$$\n",
    "follows a Student's $t$ distribution, e.g., when the sample mean $\\bar{u}$ is compared with the known true mean $\\mu$ but the standard deviation is unknown, and the sample size $N$ is small. Under the null hypothesis $H_0$ it is assumed that the sample mean $\\bar{u}$ does not show a significant difference from the true mean $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this test, we repeat the numerical $z$ test exercise with a small sample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the true parameters of the underlying normal distribution.\n",
    "TrueMean = 3\n",
    "print('True mean           : {:3f}'.format(TrueMean))\n",
    "TrueStd = 5\n",
    "### Obtain a sample drawn from the underlying normal distribution.\n",
    "N = SampleSize = 10\n",
    "print('Sample size         : {}'.format(SampleSize))\n",
    "data = scipy.stats.norm.rvs(loc=TrueMean,scale=TrueStd,size=SampleSize)\n",
    "### Compute sample statistics.\n",
    "SampleMean = np.mean(data)\n",
    "SampleStd = np.std(data,ddof=1)\n",
    "print('Sample mean         : {:3f}'.format(SampleMean))\n",
    "print('Sample std          : {:3f}'.format(SampleStd))\n",
    "### Compute test statistic.\n",
    "TestStat = (SampleMean-TrueMean)/(SampleStd/np.sqrt(SampleSize))\n",
    "### Compute the probability value (p value).\n",
    "ProbVal = 2*scipy.stats.t.cdf(-np.abs(TestStat),df=SampleSize-1)\n",
    "print('* Test statistic    : {:3f}'.format(TestStat))\n",
    "print('* Probability value : {:3f}'.format(ProbVal))\n",
    "### Check how the p value compares with the significance level alpha.\n",
    "if ProbVal >= alpha:\n",
    "    print('No significant difference between sample mean and true mean.')\n",
    "else:\n",
    "    print('Statistically significant difference between sample mean and true mean.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test is implemented in the function ``ttest_1samp()`` of the ``scipy.stats`` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute the test statistic and the probability value (p value).\n",
    "TestStat,ProbVal = scipy.stats.ttest_1samp(data,TrueMean)\n",
    "print('Test statistic    : {:3f}'.format(TestStat))\n",
    "print('Probability value : {:3f}'.format(ProbVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Two-sample $t$ test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consult the literature on the two-sample $t$ test, and then the documentation of ``scipy.stats.ttest_ind()`` to learn how the test is implemented. Following the examples above, generate two samples of random variates and demonstrate the usage of the function ``ttest_ind()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several normality tests are implemented in ``scipy.stats``. D'Agostino's $K^2$ test is based on the sample skewness and the sample kurtosis. In the Anderson-Darling test, the test statistic is constructed using the empirical CDF. The Shapiro-Wilk test is related to the normal Q-Q (quantile-quantile) plot, see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = SampleSize = 100\n",
    "print('Sample size         : {}'.format(SampleSize))\n",
    "#.. Generate a sample drawn from a normal distribution.\n",
    "data1 = scipy.stats.norm.rvs(size=SampleSize)\n",
    "TestStat,ProbVal = scipy.stats.shapiro(data1)\n",
    "print('\\nFirst sample (normal distribution)')\n",
    "print('* Test statistic    : {:3f}'.format(TestStat))\n",
    "print('* Probability value : {:3f}'.format(ProbVal))\n",
    "if ProbVal >= alpha:\n",
    "    print('No support for rejecting the normality hypothesis.')\n",
    "else:\n",
    "    print('Reject the normality hypothesis.')\n",
    "#.. Generate a sample drawn from a uniform distribution.\n",
    "data2 = scipy.stats.uniform.rvs(size=SampleSize)\n",
    "TestStat,ProbVal = scipy.stats.shapiro(data2)\n",
    "print('\\nSecond sample (uniform distribution)')\n",
    "print('* Test statistic    : {:3f}'.format(TestStat))\n",
    "print('* Probability value : {:3f}'.format(ProbVal))\n",
    "if ProbVal >= alpha:\n",
    "    print('No support for rejecting the normality hypothesis.')\n",
    "else:\n",
    "    print('Reject the normality hypothesis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Normality tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this exercise using D'Agostino's $K^2$ test as implemented in `scipy.stats.normaltest()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal probability plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graphical means to check normality is the normal probability (Q-Q, quantile-quantile) plot. See the documentation on the function `probplot()` for further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = SampleSize = 100\n",
    "print('Sample size         : {}'.format(SampleSize))\n",
    "### Generate a sample drawn from a normal distribution.\n",
    "data1 = scipy.stats.norm.rvs(size=SampleSize)\n",
    "### Generate a sample drawn from a uniform distribution.\n",
    "data2 = scipy.stats.uniform.rvs(size=SampleSize)\n",
    "### Open plot figure\n",
    "plt.figure(figsize=(11,4))\n",
    "### Normal probability plot for the first sample.\n",
    "plt.subplot(1,2,1)\n",
    "scipy.stats.probplot(data1,plot=plt,fit=True)\n",
    "plt.title('Normal probability plot for the 1st sample')\n",
    "plt.xlabel('Theoretical quantiles (standard Gaussian)')\n",
    "plt.ylabel('Empirical quantiles (ordered data)')\n",
    "plt.grid()\n",
    "### Normal probability plot for the second sample.\n",
    "plt.subplot(1,2,2)\n",
    "scipy.stats.probplot(data2,plot=plt,fit=True)\n",
    "plt.title('Normal probability plot for the 2nd sample')\n",
    "plt.xlabel('Theoretical quantiles (standard Gaussian)')\n",
    "plt.ylabel('Empirical quantiles (ordered data)')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear pattern in the normal probability plot on the left offers strong evidence for the normality hypothesis, and the linear correlation coefficient is very close to one. The intercept of the regression line gives an estimate of the mean, and the slope an estimate of the standard deviation. In the diagram on the right, the probability plot displays a nonlinear pattern, particularly away from the center, with the first few points above the line and the last few points below the line (S-shaped pattern), indicative of a symmetric distribution with short tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Normal probability plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consult the section [Normal Probability Plot](https://www.itl.nist.gov/div898/handbook/eda/section3/normprp1.htm) of the online [NIST/SEMATECH e-Handbook of Statistical Methods](http://www.itl.nist.gov/div898/handbook/) to learn how to interpret normal probability plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(99)\n",
    "u = rng.random(1000)\n",
    "x = np.array([-0.5,-0.0001,0.0,1.0,1.0001,1.5])\n",
    "d = np.ones(len(x))\n",
    "d[x<0] = 0\n",
    "d[x>1] = 0\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x,d,label='Theoretical PDF')\n",
    "plt.hist(u,bins=20,density=True,label='Empirical PDF')\n",
    "plt.title('Uniform distribution and random numbers: histogram')\n",
    "plt.xlim((-0.5,1.5))\n",
    "plt.ylim((0.0,1.5))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(x,d,label='Theoretical PDF')\n",
    "kdeplot(u,fill=True,label='Empirical PDF')\n",
    "plt.title('Uniform distribution and random numbers: KDE plot')\n",
    "plt.xlim((-0.5,1.5))\n",
    "plt.ylim((0.0,1.5))\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Normal distribution in `scipy.stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard normal distribution\n",
    "print('Normal distribution: mean=0, std=1')\n",
    "nrv1 = scipy.stats.norm()\n",
    "print('* Support:',nrv1.support())\n",
    "m,v,s,k = nrv1.stats(moments='mvsk')\n",
    "print('* Moments: m={:.2f}, v={:.4f}, s={:.2f}, k={:.3f}'.format(m,v,s,k))\n",
    "print()\n",
    "### Normal distribution with \n",
    "print('Normal distribution: mean=-1, std=2')\n",
    "uloc = -1\n",
    "usca = 2\n",
    "nrv2 = scipy.stats.norm(loc=uloc,scale=usca)\n",
    "print('* Support:',nrv2.support())\n",
    "m,v,s,k = nrv2.stats(moments='mvsk')\n",
    "print('* Moments: m={:.2f}, v={:.4f}, s={:.2f}, k={:.3f}'.format(m,v,s,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-7,5,121)\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(131)\n",
    "plt.title('Probability density functions')\n",
    "plt.plot(x,nrv1.pdf(x),'b-',lw=3,label='Standard normal')\n",
    "plt.plot(x,nrv2.pdf(x),'r-',lw=3,label='loc={:}, scale={:}'.format(uloc,usca))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(132)\n",
    "plt.title('Cumulative distribution functions')\n",
    "plt.plot(x,nrv1.cdf(x),'b-',lw=3,label='Standard normal')\n",
    "plt.plot(x,nrv2.cdf(x),'r-',lw=3,label='loc={:}, scale={:}'.format(uloc,usca))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.subplot(133)\n",
    "q = np.linspace(0,1,101)\n",
    "plt.title('Percent point (quantile) functions')\n",
    "plt.plot(q,nrv1.ppf(q),'b-',lw=3,label='Standard normal')\n",
    "plt.plot(q,nrv2.ppf(q),'r-',lw=3,label='loc={:}, scale={:}'.format(uloc,usca))\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: $z$ test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the true parameters of the underlying uniform distribution.\n",
    "TrueMean = 0.5\n",
    "TrueStd = 1/np.sqrt(12)\n",
    "### Initialize arrays to store statistics of the ensemble of samples.\n",
    "N = SampleSize = 100\n",
    "NumSamples = 1000\n",
    "SampleMeanArr = np.zeros(NumSamples)\n",
    "TestStatArr = np.zeros(NumSamples)\n",
    "ProbValArr = np.zeros(NumSamples)\n",
    "### Create arrays with sample statistics and test statistics.\n",
    "for k in range(NumSamples):\n",
    "    data = scipy.stats.uniform.rvs(size=SampleSize)\n",
    "    SampleMeanArr[k] = np.mean(data)\n",
    "    TestStatArr[k] = (SampleMeanArr[k]-TrueMean)/(TrueStd/np.sqrt(SampleSize))\n",
    "    ProbValArr[k] = 2*scipy.stats.norm.cdf(-np.abs(TestStatArr[k]))\n",
    "### Open plot figure.\n",
    "plt.figure(figsize=(11,4))\n",
    "### Plot distribution of test statistics.\n",
    "plt.subplot(1,2,1)\n",
    "epdf,bins,pats = plt.hist(TestStatArr,20,density=True)\n",
    "plt.plot(bins,scipy.stats.norm.pdf(bins),color='orange')\n",
    "plt.title('Distribution of test statistics')\n",
    "plt.xlabel(r'Test statistic $z$')\n",
    "plt.ylabel('Normed PDF')\n",
    "zCrit = scipy.stats.norm.ppf(alpha/2)\n",
    "plt.plot([zCrit,zCrit],[0,scipy.stats.norm.pdf(zCrit)],color='red')\n",
    "plt.plot([-zCrit,-zCrit],[0,scipy.stats.norm.pdf(-zCrit)],color='red')\n",
    "### Plot distribution of probability values.\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(ProbValArr,20)\n",
    "ylimits = plt.gca().get_ylim()\n",
    "plt.plot([alpha,alpha],ylimits,color='red')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim(ylimits)\n",
    "plt.title(r'Distribution of $p$ values (two-tailed $z$ test)')\n",
    "plt.xlabel('Binned $p$ values')\n",
    "plt.ylabel('Occurence frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Two-sample $t$ test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the true parameters of the underlying normal distributions.\n",
    "TrueMean1 = 3\n",
    "print('True mean (1)     : {:3f}'.format(TrueMean1))\n",
    "TrueStd1 = 5\n",
    "TrueMean2 = TrueMean1\n",
    "print('True mean (2)     : {:3f}'.format(TrueMean2))\n",
    "TrueStd2 = TrueStd1\n",
    "### Obtain two samples drawn from the underlying normal distributions.\n",
    "N = SampleSize = 10\n",
    "print('Sample size       : {}'.format(SampleSize))\n",
    "data1 = scipy.stats.norm.rvs(loc=TrueMean1,scale=TrueStd1,size=SampleSize)\n",
    "SampleMean1 = np.mean(data1)\n",
    "print('Sample mean (1)   : {:3f}'.format(SampleMean1))\n",
    "data2 = scipy.stats.norm.rvs(loc=TrueMean2,scale=TrueStd2,size=SampleSize)\n",
    "SampleMean2 = np.mean(data2)\n",
    "print('Sample mean (2)   : {:3f}'.format(SampleMean2))\n",
    "### Compute the test statistic and the probability value (p value).\n",
    "TestStat,ProbVal = scipy.stats.ttest_ind(data1,data2)\n",
    "print('* Test statistic    : {:3f}'.format(TestStat))\n",
    "print('* Probability value : {:3f}'.format(ProbVal))\n",
    "### Check how the p value compares with the significance level alpha.\n",
    "if ProbVal >= alpha:\n",
    "    print('No significant difference between the sample means.')\n",
    "else:\n",
    "    print('Significant difference between the sample means.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Normality tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = SampleSize = 100\n",
    "print('Sample size         : {}'.format(SampleSize))\n",
    "#.. Generate a sample drawn from a normal distribution.\n",
    "data1 = scipy.stats.norm.rvs(size=SampleSize)\n",
    "TestStat,ProbVal = scipy.stats.normaltest(data1)\n",
    "print('\\nFirst sample (normal distribution)')\n",
    "print('* Test statistic    : {:3f}'.format(TestStat))\n",
    "print('* Probability value : {:3f}'.format(ProbVal))\n",
    "if ProbVal >= alpha:\n",
    "    print('No support for rejecting the normality hypothesis.')\n",
    "else:\n",
    "    print('Reject the normality hypothesis.')\n",
    "#.. Generate a sample drawn from a uniform distribution.\n",
    "data2 = scipy.stats.uniform.rvs(size=SampleSize)\n",
    "TestStat,ProbVal = scipy.stats.normaltest(data2)\n",
    "print('\\nSecond sample (uniform distribution)')\n",
    "print('* Test statistic    : {:3f}'.format(TestStat))\n",
    "print('* Probability value : {:3f}'.format(ProbVal))\n",
    "if ProbVal >= alpha:\n",
    "    print('No support for rejecting the normality hypothesis.')\n",
    "else:\n",
    "    print('Reject the normality hypothesis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
